\input{../EncabezadoTesis}
\begin{document}

\justifying

\section{Machine Learning}

  \par Existen numerosos autores que han definido el concepto de que una máquina
    aprende, en este trabajo hemos extraído una en particular que resulta
    clara y no ambigua
    \begin{framed}
      \begin{center}
        \textit{Se dice que un programa de computadora \textbf{aprende} de experiencia
        $E$ con respecto a alguna tarea $T$ y una métrica de rendimiento $M$, si
        con la experiencia $E$ se incrementa su rendimiento en la tarea $T$,
        medida por $M$.}\\
      \end{center}
      \centering \textbf{Tom Mitchell, 1997} \cite{mitchell_learn}
    \end{framed}

    También, en el mismo libro, Mitchell enuncia que el campo del aprendizaje
    automático se refiere a la cuestión de cómo contruir programas de
    que mejoren automáticamente con experiencia.
    En ese marco, podemos decir que el \textit{Aprendizaje Automático} (ML) es un
    enfoque empírico efectivo para regresiones y/o clasificaciones de sistemas
    lineales y no lineales, que pueden involucrar desde unos pocos hasta varios
    cientos de variables.

  \par Además, los métodos de ML se pueden clasificar en
    \textit{supervisados}\cite{supervised_learning} y
    \textit{no-supervisados}\cite{unsupervised_learning}, aunque hoy en día
    existen matices entre estas dos clases\cite{semi_supervised}.
    Los algoritmos que aprenden a través de métodos supervisados son aquellos que
    aprenden una función que mapea un valor de entrada a uno de salida basado
    en pares de ejemplos entrada-salida.
    El caso de los algoritmos que utilizan métodos no-supervisados aprenden
    realizando inferencia de la función que describe la estructura de los datos
    de ejemplo. En este caso, los datos de entrenamiento del algoritmo no son
    etiquetados (no existen pares entrada-salida de ejemplo).

  \par En general, el enfoque de ML requiere entrenamiento utilizando un
    conjunto de datos que sea representativo del conjunto del problema.
    Es fundamental para el correcto
    Se debe seleccionar un conjunto de datos que se utilizará,
    luego del entrenamiento del modelo, para validación del mismo\cite{test_val}.
    ML es ideal para aquellos problemas en donde el conocimiento teórico del mismo
    es incompleto o insuficiente, pero se cuenta con un gran conjunto de observaciones.


  ML ha mostrado ser de utilidad para un gran número de aplicaciones en Geociencias
  relacionadas a la tierra, oceanos y atmósfera, y en algoritmos de extracción
  de información bio-geofísica.
  Algunos de los algoritmos de ML más usados en aplicaciones relativas a
  Geociencias y Sensado Remoto (GRS) son las Redes Neuronales Artificiales (ANN),
  Support Vector Machines (SVM), Mapas Auto-organizados (SOM), Árboles de Decisión (DT),
  Random Forests y Algoritmos Genéticos. Su aplicación en problemas de GRS es
  relativamente nuevo y extremádamente prometedora. En particular, ANNs son
  usadas para clasifición pero también son usadas para la aplicación en pronósticos
  relativos a series de tiempo.
  De hecho, una exploración en la base bibliográfica Scopus devuelve más de 4000
  publicaciones que incluyen \textit{remote sensing} y \textit{neural network},
  311 de ellas en 2016. De ese total, el 45\% corresponde a
  \textit{Sciences of the Earth}, el 44\% a \textit{Computer Science} y el 35\% a
  \textit{Engineering}; con China, Estados Unidos, Italia e India como los paises
  con mayor producción científica en dichas áreas.


\subsection{Scikit-learn}

  \par \textit{Scikit-learn}\cite{scikit-learn, sklearn_review} es un módulo
    de Python de libre acceso para Aprendizaje Automático
    construido sobre \textit{SciPy}\cite{scipy}. Es una herramienta
    sencilla y efectiva para minería de datos y análisis de datos. Dado que está bajo
    licencia \textit{BSD}, esta librería puede ser utilizada tanto
    para uso personal como comercial.

  \par Éste proyecto inició en el 2007 como un proyecto del \textit{Google Summer Scool} por David
    Cournapeau. Más tarde ese año, Matthieu Brucher comenzó a trabajar en éste proyecto
    como parte de su tesis. En 2010 Fabian Pedrafosa, Gael Varoquaux, Alexandre
    Gramfort y Vincent Michel del INRIA \footnote{Institut National de Recherche
    en Informatique et en Automatique} tomaron el liderazgo del proyecto y lo liberaron
    al público por primera vez, el 1ro de Febrero de 2010. Desde entonces, salieron muchos
    \textit{releases} siguiendo ciclos de 3 meses, y una gran comunidad internacional
    ha estado liderando el desarrollo desde entonces.

  \par Con scikit-learn, los usuarios pueden realizar una gran variedad de tareas
    que van desde selección de modelos, clustering, y preprocesamiento de datos, entre otras.
    La librería provee un completo conjunto de tareas que permiten una
    implementación completa de la solución de un problema de Aprendizaje Automático.

    Por las razones mencionadas es que tiene una muy extensiva utilización.
    Se está utilizando tanto para uso científico
    grandes compañias en diferentes industrias desde streaming de música, hasta
    recomendadores de hoteles, entre otras. Esto da la pauta de que los usuarios pueden
    integrar algoritmos implementados con este módulo a sus propias aplicaciones.

Otra de las grandes bondades de la herramienta es que se asegura que tanto usuarios
antiguos como nuevos puedan obtener la asistencia que necesitan para integrar
el módulo de Aprendizaje Automático a sus propias plataformas. Ésta es la razón
que justifica el alto nivel de detalle en su documentación oficial.



\subsection{Métodos Lineales}

\subsubsection{Regresión lineal utilizando el método ordinario de Mínimos Cuadrados}

\subsubsection{Regresión lineal utilizando el método Ridge}


\subsection{Árboles de Decisión}
  \par Los \textit{Árboles de Decisión} (DTs)\cite{decision_tree_regression}
    son métodos no paramétricos de aprendizaje supervisado
    utilizados tanto para problemas de clasificación como de regresión.
    La meta es crear un modelo que prediga el valor de una variable objetivo aprendiendo
    simples reglas de decisión inferidas a partir de las características de los datos
    de entrenamiento.


  \par El algoritmo de los DT construye modelos de clasificación o regresión
    utilizando una estructura arbórea. Éste divide el conjunto de datos en pequeños
    subconjuntos mientras que, al mismo tiempo, un árbol de decisión es incrementalmente
    construido. El resultado final es un árbol con nodos de decisión y nodos hojas.
    Un nodo de decisión tiene dos o más ramas, cada una representando valores para
    el atributo examinado. Un nodo hoja representa una decisión dentro del
    objetivo numérico. Los árboles de decisión pueden manejar tanto datos
    categóricos como numéricos.


  \par Más formalmente, dados los vectores de entrenamiento $x_{i} \in R^{n}$, $i = 1,..,l$
    y un vector de etiquetas $y \in R^{l}$, un árbol de decisión particiona
    recursivamente el espacio de modo que las muestras con la misma etiqueta se agrupen juntas.


  \par Supongamos que los datos en el nodo $m$ son representados por $Q$. Para cada
    candidato se divide $\theta = (j, t_{m})$ donde $j$ es una característica y
    $t_{m}$ es un humbral, particionando los datos en conjuntos $Q_{izq}(\theta)$ y
    $Q_{der}(\theta)$ donde:
    \begin{align}
      Q_{izq}(\theta) &= (x, y) | x_{j} \leq t_m \\
      Q_{der}(\theta) &= Q - Q_{izq}(\theta)
    \end{align}
    La impureza en $m$ es calculada usando la función de impureza $H()$, la elección
    de ésta depende de la tarea que se quiera realizar.
    En el caso de una regresión, para el nodo $m$, representando una
    región $R_{m}$ con una cantidad $N_{m}$ observaciones, los criterios
    para minimizar en cuanto a la determinación de ubicaciones para divisiones
    futuras suelen ser el \textbf{Error Cuadrático Medio}, que minimiza el error $L2$ usando
    valores promedios en los nodos terminales, y el \textbf{Error Absoluto Medio}, que minimiza
    el error $L1$ usando el valor de la mediana estadística en los nodos terminales.
    Luego, la función de impureza es
    \begin{align}
      G(Q, \theta) = \frac{n_{izq}}{N_{m}} \ H(Q_{izq}(\theta)) + \frac{n_{der}}{N_{m}} \ H(Q_{der}(\theta))
    \end{align}
    y se seleccionan los parámetros que minimicen la impureza tal como expresa la
    siguiente ecuación
    \begin{align}
      \theta^{*} = argmin_{\theta} \ G(Q, \theta)
    \end{align}

    Luego se sigue partiendo $Q_{izq}$ y $Q_{der}$ hasta que se alcance la profundidad
    máxima permitida del árbol, $N_{m} < min_{muestras}$ o bien $N_{m} = 1$


\subsection{Random Forest}

  \par \textit{Random Forest} (RF) es un método de aprendizaje que utiliza ensamblado y se
    usa para llevar a cabo tareas tanto de clasificación como de regresión.
    La idea es construir una variedad de árboles de decisión en tiempo de entrenamiento
    y devolver la clase que se corresponda con la moda estadística de las clases
    (para clasifición) o bien el promedio (para regresión) de los resultados
    obtenidos por los árboles individuales.

  \par Existen varios algoritmos de RF, describiremos formalmente el desarrollado
    por Breiman \cite{random_forest}.
    Sea $\mathcal{D}_{n} = \ \{ (X_{1}, Y_{1}), \ \dots, \ (X_{n}, Y_{n})\}$
    un conjunto de variables aleatorias independientes e idénticamente distribuídas (i.i.d.)
    pertenecientes al conjunto $[0,1]^{d} \ \times \ \Re $ con $d \geq 2$,
    con la misma distribución que un par genérico $(X,Y)$ satisfaciendo que
    $\mathbbm{E}Y^{2} < \infty$. Además, sea $r()$ la función de regresión que se busca estimar.

  \par Un RF es un predictor que consiste de una colección aleatoria base
    de árboles de regresión, $\{ r_{n}(x, \theta_{m}, \mathcal{D}_{n}), m \ > \ 1 \}$, donde
    $\theta_{1},\ \theta_{2},\ \dots$ son salidas i.i.d. de una variable aleatoria
    $\theta$. Éstos árboles aleatorios son combinados para formar la estimación
    de la regresión:

    \begin{align}
      \overline{r}(X,\ \mathcal{D}_{n})\ =\ \mathbbm{E}_{\theta}[r_{n}(X,\ \theta,\ \mathcal{D}_{n})]
    \end{align}

    donde $\mathbbm{E}_{\theta}$ denota la esperanza con respecto al parámetro aleatorio
    condicionada por $X$ y el conjunto de datos $\mathcal{D}_{n}$. Notemos que
    dicha esperanza es evualuada por el método de Monte Carlo\cite{monte_carlo},
    esto es, generando $M$ árboles aleatorios, y tomando el promedio de los resultados.
    La variable de aleatoriedad $\theta$ es usada para determinar cómo se van a realizar los
    sucesivos cortes cuando se construyen los árboles individuales, como una selección
    de la coordenada a dividir y la posición de la división.

  \par Cada árbol aleatorio es construido de la siguiente manera: todos los nodos
    del árbol son asociados a celdas rectangulares tales que en cada etapa de
    construcción del árbol, el conjunto de celdas asociadas a las hojas del árbol
    forman una partición de $[0, 1]^{d}$. La raíz del árbol es exactamente $[0, 1]^{d}$.
    Luego, el siguiente procedimiento es repetido una cantidad $\lceil \log_{2}k_{n} \rceil$ veces
    donde $k_{n}$ es un parámetro determinístico, fijado por el usuario, posiblemente
    dependiente del valor de $n$.

    \begin{enumerate}
      \item En cada nodo, se selecciona una coordenada de $X = (X^{(1)}, \ \dots,\ X^{(d)})$
            donde la característica j-ésima tiene una probabilidad de $p_{nj} \in (0,1)$
            de ser elegida.
      \item En cada nodo, una vez que la coordenada es seleccionada, la división es
            en el punto intermedio del lado elegido.
    \end{enumerate}

    Cada árbol aleatorio $r_{n}(X, \theta)$ devuelve el promedio sobre todos los
    $Y_{i}$ para los cuales los vectores correspondientes $X_{i}$ caen en la misma
    celda de la partición aleatoria que $X$.


\subsection{K-Vecinos más cercanos (KNN)}
  \par El principio detrás de los métodos de vecinos más cercanos es encontrar un
    número predefinido de las muestras de entrenamiento más cercanas en distancia
    al nuevo punto, y predecir su valor a partir de ellos.
    El número de muestras puede ser una constante definida por el usuario, o
    variar basada en la densidad local de los puntos. La distancia puede, en general,
    ser cualquier métrica aunque la distancia Euclídea es la elección más común.

  \par Las predicciones son hechas para un nuevo punto $x$, buscando a través del conjunto
    de entrenamiento completo las $K$ instancias más cercanas (los vecinos) y computar
    la variable de retorno utilizando la información de esos K puntos. Para el caso
    de la regresión suele ser el promedio de cada variable de retorno de la siguiente
    manera

    \begin{align}
      \overline{y}(x) = \frac{1}{k} * \sum_{j \in knn(x)} y_{j}
    \end{align}



\subsection{Support Vector Machine (SVM)}

  \begin{figure}
  \centering%
  \includegraphics[width=0.5\textwidth]{images/svm_hiperplane}%
  \caption{Plano de separación de clases generado por una SVM}\label{fig:svm}
  \end{figure}

  \par Una \textit{Support Vector Machine} (SVM) \cite{first_svm} construye un
    hiperplano o un conjunto de hiperplanos en un espacio
    de muy alta, o infinta, dimensionalidad. Éstos pueden ser usados tanto para
    tareas de regresión como de clasifición. Intuitivamente, una buena separación
    se consigue por el hiperplano que tenga la mayor distancia a los puntos de
    entrenamiento más cercanos de alguna clase, como se puede observar en la
    Figura \ref{fig:svm}, dado que en general
    a más grande sea esa distancia más pequeño será el error de generalización del
    modelo.

  \par \textit{Support Vector Regression} (SVR)\cite{support_vector_regression, review_svr}
    es una veloz y precisa forma de interpolación de conjuntos de datos.
    Es útil cuando se quiere aproximar una función costosa de calcular sobre un
    dominio conocido. Aprende rápidamente y se puede mejorar sistemáticamente.

  \par SVR es una generalización de la SVM a problemas de regresión. Tecnicamente,
    se puede decir que es un algoritmo de aprendizaje supervisado. Éste
    requiere de un conjunto de datos de entrenamiento,
    $\mathcal{T} = (\vec{X}, \vec{Y})$, que cubre el dominio de interés acompañado
    de las soluciones en dicho dominio. El trabajo de la SVM es aproximar la función
    definida por el conjnuto de entrenamiento, $F(\vec{X}) = \vec{Y}$. En general,
    en las SVM, los vectores $\vec{X}$ son utilizados para definir el hiperplano que
    separa las distintas soluciones posibles. En problemas de regresión, estos
    vectores son utilizados para realizar una regresión lineal, los que estén
    más cerca del punto de prueba se los llama \textit{vectores de soporte}.

    Daremos una idea más detallada de los fundamentos matemáticos detrás de una
    SVR \cite{svr_tutorial}:

    Dados los vectores de entrenamiento $x_{i} \in \mathbb{R}^{p}$ con $i = 1, \dots ,n$
    y un vector $y \in \mathbb{R}$ el $\epsilon$-SVR resuelve el siguiente problema
    primario:

    \begin{align}
      \min\limits_{w, b, \zeta, \zeta^{*}} \frac{1}{2} w^{T} w + C \sum_{i = 1}^{n} \zeta_{i}
    \end{align}
    con las restricciones de:


    \begin{math}
      y_{i} - w^{T} \phi(x_{i}) - b \leq \epsilon + \zeta_{i}, \\
      w^{T} \phi(x_{i}) + b - y_{i} \leq \epsilon + \zeta^{*}_{i}, \\
            \zeta^{*}_{i}, \zeta_{i} \geq 0 \\
      para\ i\ =\ 1,\ \dots, n
    \end{math}

    Mientras que el problema dual a resolver es:

    \begin{align}
      \min\limits{\alpha, \alpha^{*}} \frac{1}{2} (\alpha - \alpha^{*})^{T}
      Q(\alpha - \alpha^{*}) + \epsilon e^{T} (\alpha + \alpha^{*}) -
      y^{T} (\alpha - \alpha^{*})
    \end{align}
    con las restricciones de:

    \begin{math}
      e^{T} (\alpha - \alpha^{*}) = 0, \\
      0 \geq \alpha, \alpha^{*} \leq C \\
      para\ i\ =\ 1, \dots, n
    \end{math}

  \par Donde $e$ es un vector para el cual todos sus componentes poseen el valor $1$, $C > 0$
    es la cota superior, $Q$ es una matriz semidefinida
    positiva\footnote{Una matriz, $M$, es semidefinida positiva si $x^{*}Mx \leq 0$
    $\forall x \in \mathbb{R}^{n}$} de tamaño $n \times n$,
    $Q_{ij} \equiv K(x_{i}, x_{j}) = \phi(x_{i}^{T})\phi(x_{j})$ es el núcleo
    (\textit{kernel}, en inglés). Aquí, los vectores de entrenamiento están siendo mapeados
    a un espacio de gran (probablemente infinita) dimensionalidad por la función
    $\phi$.
    Luego, la función de decisión es:
    \begin{align}
      \sum_{i = 1}^{n} (\alpha - \alpha^{*})K(x_{i}, x) + \rho
    \end{align}

\subsection{Perceptron Multicapa (MLP)}
    \begin{figure}
    \centering%
    \includegraphics[width=0.7\textwidth]{images/ejemplo_mlp}%
    \caption{Arquitectura de una MLP de cuatro variables de entrada, una capa
            oculta de cinco neuronas y un sólo valor de salida}\label{fig:mlp}
    \end{figure}

  \par Un \textbf{Perceptron Multicapa} (MLP)\cite{mlp_intro1, mlp_intro2} es un tipo
    de red neuronal artificial (ANN) \textit{feedforward}.
    Éste es un algoritmo de aprendizaje supervisado que logra distinguir
    relaciones entre datos que no sean linealmente separables, aprende una función
    a partir de un conjunto de datos de entrenamiento y puede ser
    utilizada tanto para tareas de regresión como de clasificación haciendo uso, entre
    otras cosas, de una técnica llamada \textit{propagación hacia atrás}\cite{backpropagation}
    (\textit{backpropagation}, en inglés).
    El MLP consiste de al menos tres capas: una de entrada, una de salida y,
    como mínimo, una capa oculta\footnote{Una capa de neuronas artificiales que toman un conjunto
    de entradas ponderadas y producen una salida a través de una función de activación.};
    la vista gráfica de una arquitectura simple se puede observar en la
    Figura \ref{fig:mlp}.

  \par Una descripción matemática simplificada del algoritmo en cuestión es la
    que se menciona a continuación.
    Dados ejemplos de entrenamiento $(x_{1}, y_{1}), \dots, (x_{n}, y_{n})$
    donde $x_{i} \in \mathbb{R}^{n}$ y $y_{i} \in \{0,1\}$, un MLP de una capa oculta
    con una neurona aprende una función $f(x) = W_{2}g(W_{1}^{T} x + b_{1}) + b_{2}$
    donde $W_{1} \in \mathbb{R}^{m}$ y $W_{2}, b_{1}, b_{2} \in \mathbb{R}$ son
    parámetros del modelo. $W_{1}, W_{2}$ representan los pesos de la capa de entrada y la
    capa oculta, respectivamente. $b_{1}, b_{2}$ representan el sesgo agregado a
    la capa oculta y la capa de salida, respectivamente. La función
    $g(): \mathbb{R} \rightarrow \mathbb{R}$ es la función de activación, la cual
    es definida por defecto como la tangente hiperbólica. Está dada por,

    \begin{align}
      g(z) = \frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}
    \end{align}

    En problemas de regresión, la salida del algoritmo es $f(x)$, por lo que la
    función de activación de salida es simplemente la función identidad. En estos
    problemas, MLP también utiliza como función de pérdida la correspondiente
    al \textit{Error Cuadrático}:
    \begin{align}
      Loss(\hat{y}, y, W) = \frac{1}{2} \norm{\hat{y} - y}^{2}_{2} + \frac{\alpha}{2} \norm{W}^{2}_{2}
    \end{align}

  \par Comenzando desde pesos con valores aleatorios, el MLP minimiza la función de
    pérdida actualizando repetidamente dichos pesos. Luego de calcular la pérdida,
    se propaga desde la capa de salida a todas las anteriores (\textit{backpropagation}),
    proporcionando un valor de peso a cada parámetros para disminuir la pérdida.
    Para ello, se utiliza \textit{descenso por gradiente}, en el cual el
    gradiente $\nabla Loss_{W}$ de la pérdida con respecto a los pesos es
    calculada y deducida de W.
    Más formalmente, es expresado como:
    \begin{align}
      W^{i + 1} = W^{i} - \epsilon \nabla Loss^{i}_{W}
    \end{align}
    donde $i$ es el paso de iteración, y $\epsilon > 0$ es la taza de aprendizaje.

    En general el algoritmo termina cuando se alcanza cierto número definido por el
    usuario de iteraciones o se cruza un humbral para la pérdida.



\end{document}
